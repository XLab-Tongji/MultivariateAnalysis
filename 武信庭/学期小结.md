# 学期工作小结

> 作者：
>
> 1851007 武信庭

## 1. 算法原理介绍

#### 多变量时间序列预测的传统方法

[Normalizing Kalman Filtersfor Multivariate Time Series Analysis]: https://proceedings.neurips.cc/paper/2020/file/1f47cef5e38c952f94c5d61726027439-Paper.pdf

如上论文提到的方法：”经典的方法是**扩展标准的单变量模型**，**产生向量自回归**、**多变量GARCH**和**多变量状态空间模型**“

预测方法：**VAR**（Vector Auto Regression 向量自回归）

方法概述：https://www.analyticsvidhya.com/blog/2018/09/multivariate-time-series-guide-forecasting-modeling-python-codes/

#### 多变量时间序列平稳性检测方法

对应单变量时间序列中的ADF检验方法，多变量中的平稳性检测使用：Johansen

如果两组序列都是非平稳的，但是经过一阶差分后是平稳的，且这两组序列经过某种线性组合也是平稳的，则它们之间就存在协整关系

协整理论的意义在于：

1. 首先，因为或许单个序列是非平稳的，但是通过协整我们可以建立起两个或者多个序列之间的平稳关系，进而充分应用平稳性的性质。

2. 其次，可以避免伪回归。如果一组非平稳的时间序列不存在协整关系，那么根据它们构造的回归模型就可能是伪回归。

3. 区别变量之间长期均衡关系和短期波动关系。

用Johansen Test 来进行协整检验，它的思想是采用极大似然估计来检验多变量之间的协整关系

https://www.itbook5.com/2019/08/11551/

https://towardsdatascience.com/vector-autoregressions-vector-error-correction-multivariate-model-a69daf6ab618



## 2. 算法实验配置与结果

### 2.1 第二周实验：

#### 方法介绍：

多变量时间序列预测传统方法中最常用的方法之一，向量自回归VAR。在VAR中，每个变量是其自身过去值和所有其他变量的过去值的线性函数

#### 使用VAR的原因：

与单变量时间序列预测方法中常用的AR不同，VAR能够理解和使用多个变量之间的关系，这有助于描述数据的动态行为，并提供更好的预测结果，故在多变量时间序列预测任务中传统方法常采用VAR

#### 平稳性检测：

通过研究单变量概念，我们知道，平稳时间序列往往会给我们一组更好的预测，类似于单变量序列的增强Dickey-Fuller检验，我们有用来检验任何多变量时间序列数据的平稳性的Johansen检验

#### 代码实现：

详细代码见git仓库下代码，以下介绍大致实现思路

1. 读取数据：从CSV中读取源数据
2. 预处理：修改日期类型，删除原索引并建立日期索引，缺失值处理（用上一时间段非空数据填补）
3. 检查平稳性：Johansen检验方法检查数据平稳性
4. 划分数据集：划分训练集（80%）与验证集（20%）
5. 模型训练：用VAR方法训练模型
6. 模型预测：在训练集上预测
7. 检查效果：检查预测模型中各指标的RMSE值

#### 实验结果：

```python
rmse value for CO(GT) is :  25.8450254588291
rmse value for PT08.S1(CO) is :  22.129426065746735
rmse value for NMHC(GT) is :  20.864380053887952
rmse value for C6H6(GT) is :  21.256285958018466
rmse value for PT08.S2(NMHC) is :  101.08862440205581
rmse value for NOx(GT) is :  101.30647101396487
rmse value for PT08.S3(NOx) is :  42.22870719219117
rmse value for NO2(GT) is :  59.38145416043077
rmse value for PT08.S4(NO2) is :  43.95540095250501
rmse value for PT08.S5(O3) is :  77.72330374240632
rmse value for T is :  103.3584141252896
rmse value for RH is :  111.30966033568895
rmse value for AH is :  172.5410894145241
```



### 2.2 第四周实验

修改为循环增量训练，每次预测一步，并更改实验数据集为空气污染数据集

#### 代码实现：

```python
train_len = int(0.8 * (len(data)))
left_len = int(0.2 * (len(data)))
# 创建训练集与验证集
train = data[:train_len]
valid = data[train_len:]
print("init train df is: ", train)
print("valid length is: ", left_len)

for i in range(left_len):
    # 模型训练
    model = VAR(endog=train)
    model_fit = model.fit()
    cols = data.columns

    # 在验证集上进行一步预测
    prediction = model_fit.forecast(model_fit.y, steps=1)
    # print("prediction is: ", prediction)

    ind = valid.index[i]
    # 将预测结果转为df格式并加入训练集
    train.loc[ind] = prediction[0]
    # print(train)

print("final train is:", train)
pred = train.copy(deep=True)

for i in range(0, 8):
    print('rmse value for', cols[i], 'is : ', sqrt(mean_squared_error(pred.iloc[i], valid.iloc[i])))
```

#### 实验结果：

```
final train is:                            dew       temp  ...      rain   pollution
date                                       ...                      
2010-01-02 00:00:00 -16.000000  -4.000000  ...  0.000000  129.000000
2010-01-02 01:00:00 -15.000000  -4.000000  ...  0.000000  148.000000
2010-01-02 02:00:00 -11.000000  -5.000000  ...  0.000000  159.000000
2010-01-02 03:00:00  -7.000000  -5.000000  ...  0.000000  181.000000
2010-01-02 04:00:00  -7.000000  -5.000000  ...  0.000000  138.000000
...                        ...        ...  ...       ...         ...
2014-12-31 19:00:00   1.779621  12.168487  ...  0.209939   93.251906
2014-12-31 20:00:00   1.779621  12.168487  ...  0.209939   93.251906
2014-12-31 21:00:00   1.779621  12.168487  ...  0.209939   93.251906
2014-12-31 22:00:00   1.779621  12.168487  ...  0.209939   93.251906
2014-12-31 23:00:00   1.779621  12.168487  ...  0.209939   93.251906

[43800 rows x 8 columns]
rmse value for dew is :  62.54004327229075
rmse value for temp is :  61.45001261187828
rmse value for press is :  62.25672905397457
rmse value for wnd_dir is :  65.7630239002131
rmse value for wnd_spd is :  21.802320977363856
rmse value for snow is :  8.977293578802021
rmse value for rain is :  7.433035214500197
rmse value for pollution is :  18.814345922726094
```



### 2.3 第五周实验

对实验空气污染数据集进行一阶差分并判断其平稳性

#### 对原数据进行一阶差分

差分变换是去除时间序列中系统结构的一种简单方法。我们将通过从序列中的每个值中减去前一个值来消除趋势，这就是一阶差分。简单来说，我们将做的一阶差分，即如果我们对n个时间序列有一个综合阶数，如果我们对差分和时间取一阶，我们将留下序列综合阶数为零。

实现代码如下：

```python
train_diff = train.diff().dropna()
print(train_diff)
train_diff.plot(figsize=(10, 6))
plt.show()
```



#### ADF检验

利用ADF检验，在一阶差分前后分别检验变量平稳性

实现代码如下：

```python
def adf(time_series):
    result= ts.adfuller(time_series.values)
    print(' ADF statistic:%f' % result[0])
    print(' p-value:%f' % result[1])
    print(' Critical Values:')
    for key, value in result[4]. items():
        print('\t%s:%.3f' % (key, value))
```

在得到ADF检验结果后如何确定该序列能否平稳，主要可以看两点：

1. 1%、%5、%10不同程度拒绝原假设的统计值和ADF Test result的比较，ADF Test result同时小于1%、5%、10%即说明非常好地拒绝该假设
2. P-value是否非常接近0



#### Granger causality检验

使用Granger causality检验来判断一个序列是否对预测另一个序列有用

接收一个包含2列的2维的数组作为主要参数：
第一列是当前要预测未来值的序列A，第二列是另一个序列B,该方法就是看B对A的预测是否有帮助。

该方法的零假设是：B对A没有帮助。如果所有检验下的P-Values都小于显著水平0.05，则可以拒绝零假设，并推断出B确实对A的预测有用。

实现代码如下：

```python
print(grangercausalitytests(train_diff[['dew', 'pollution']],
                            maxlag=15, addconst=True, verbose=True))
print(grangercausalitytests(train_diff[['temp', 'pollution']],
                            maxlag=15, addconst=True, verbose=True))
print(grangercausalitytests(train_diff[['press', 'pollution']],
                            maxlag=15, addconst=True, verbose=True))
print(grangercausalitytests(train_diff[['wnd_dir', 'pollution']],
                            maxlag=15, addconst=True, verbose=True))
print(grangercausalitytests(train_diff[['wnd_spd', 'pollution']],
                            maxlag=15, addconst=True, verbose=True))
print(grangercausalitytests(train_diff[['snow', 'pollution']],
                            maxlag=15, addconst=True, verbose=True))
print(grangercausalitytests(train_diff[['rain', 'pollution']],
                            maxlag=15, addconst=True, verbose=True))
```

#### 实验结果：

```python
MAE:7.875351
MSE:63.652026
RMSE:7.978222
```



## 3. 代码地址

https://github.com/zactWu/VectorAutoRegression



## 4. 算法总结

整个实验过程中主要遇到了两个困难：

首先，在前期实现算法时，VAR模型效果不佳，于是我对其进行了分析，结合查找到的资料，初步推测可能为statsmodels库中VAR模型有误，或其包含的VAR模型只能预测1-3步，故在后续实验中对此问题进行改进，手动调整预测步数与对应窗口大小。

同时，在前几次实验中平稳性检测原理也较为模糊，不能很好的检测其平稳性，故在后续实验中先后对时间序列进行一阶差分，然后利用ADF检验，在一阶差分前后分别检验变量平稳性，最后使用Granger causality检验来判断一个序列是否对预测另一个序列有用，完整检测其平稳性与协整性。

经过上述难点的思考与改进，实验结果相较起初有了一定改进，但在与深度学习模型结果相比较时仍然稍显不佳，可能是实验数据与参数调整问题，这是传统预测方法VAR的缺点，但同时在做出如上一系列实验的过程中，在自己实现VAR训练与预测的时，我也发现了VAR模型具有良好的可操作性与可解释性，相较更像黑盒的深度学习模型，VAR由自己实现，也能进行更多的调节和改进，这是VAR的优点

